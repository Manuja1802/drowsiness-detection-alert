
Project Title: Real-Time Drowsiness and Yawning Detection System

Introduction:
The Real-Time Drowsiness and Yawning Detection System is an AI-driven application designed to enhance driver safety by monitoring signs of fatigue, specifically drowsiness and yawning, through real-time video analysis. This project utilizes computer vision algorithms, facial landmark detection, and auditory alerts to detect and respond to early signs of fatigue, reducing the risks associated with drowsy driving.

Project Overview:
Drowsy driving is one of the leading causes of road accidents globally, as it impairs the driver's alertness, reflexes, and decision-making abilities. This project aims to address this issue by developing a reliable, efficient system that can detect drowsiness by analyzing the user’s eye and mouth movements. If the system detects prolonged eye closure or excessive yawning, it generates an audible alert, reminding the user to stay vigilant or take a break.

Key Functionalities:
- Eye Aspect Ratio (EAR) Calculation: The system calculates the Eye Aspect Ratio to detect prolonged eye closure, indicating drowsiness.
- Lip Distance Measurement: The system measures the distance between the upper and lower lips to detect yawning.
- Real-Time Monitoring: It continuously captures and analyzes video frames, providing a seamless and responsive user experience.
- Audible Alert System: When drowsiness or yawning is detected, an alarm sound is played to prompt the user to regain alertness.

Components and Libraries:

1. Computer Vision & Image Processing:
   - OpenCV (cv2): The OpenCV library is used to capture video from the webcam and perform image processing tasks such as grayscale conversion, contour drawing, and text overlay for alerts.
   - imutils: This library simplifies various image processing functions such as resizing frames and working with contours, making the code more readable and manageable.

2. Face Detection and Landmark Detection:
   - Haar Cascade Classifier: The haarcascade_frontalface_default.xml file, provided by OpenCV, is a pre-trained classifier for frontal face detection. It quickly detects the presence of a face in the video frame, though it may be less accurate than other methods.
   - Dlib Library: Dlib’s shape_predictor_68_face_landmarks.dat file provides a 68-point facial landmark model. This model is used to identify specific facial features like the eyes and mouth, allowing for accurate calculation of drowsiness indicators like eye closure and yawning.

3. Audio Processing:
   - Pydub: The Pydub library, along with pydub.playback, is used to handle and play audio files. This library allows the system to play an alert sound (specified by the alarm.wav file) when drowsiness or yawning is detected, prompting the user to stay attentive.

4. Distance Calculations:
   - SciPy Spatial Distance: SciPy's distance.euclidean function calculates the Euclidean distance between facial points, a crucial component for computing the Eye Aspect Ratio and Lip Distance, which are core metrics for detecting drowsiness and yawning.

Algorithms Used:

1. Eye Aspect Ratio (EAR) Calculation:
   - The Eye Aspect Ratio (EAR) algorithm measures the ratio of distances between vertical and horizontal eye landmarks. A low EAR value (below a threshold) sustained over multiple frames indicates prolonged eye closure, a sign of drowsiness. The formula used for EAR is:
     EAR = (distance(p2, p6) + distance(p3, p5)) / (2 * distance(p1, p4))
   - Threshold values:
     - EYE_AR_THRESH: A threshold value below which the EAR indicates eye closure.
     - EYE_AR_CONSEC_FRAMES: Number of consecutive frames with an EAR below the threshold to trigger an alarm.

2. Lip Distance Calculation:
   - Lip Distance measures the vertical distance between the upper and lower lip points to detect yawning. When this distance surpasses a threshold (indicating mouth opening), the system flags a potential yawn. This is calculated using the mean of top and bottom lip landmarks:
     Lip Distance = |mean(top_lip_points) - mean(bottom_lip_points)|
   - Threshold value:
     - YAWN_THRESH: A predefined threshold value above which the lip distance indicates a yawn.

Workflow:

1. Initialize and Load Files:
   - Load the haarcascade_frontalface_default.xml classifier for face detection.
   - Load the shape_predictor_68_face_landmarks.dat model for facial landmark detection.
   - Load the alarm audio file specified as alarm.wav or the user-provided path.

2. Video Capture and Frame Processing:
   - Capture video frames using OpenCV and resize each frame for efficient processing.
   - Convert frames to grayscale for faster face and landmark detection.

3. Face and Feature Detection:
   - Detect faces in each frame using Haar Cascade. For each detected face, locate eye and mouth landmarks using Dlib’s landmark predictor.
   - Calculate the EAR and Lip Distance to determine eye closure and yawning.

4. Drowsiness and Yawning Detection:
   - If EAR falls below EYE_AR_THRESH for more than EYE_AR_CONSEC_FRAMES, trigger the drowsiness alert.
   - If Lip Distance exceeds YAWN_THRESH, trigger the yawning alert.

5. Alert System:
   - Play the alarm sound using Pydub if drowsiness or yawning is detected, and display visual alerts on the video frame.

Code Arguments:
- --webcam: Specifies the webcam index (default 0).
- --alarm: Specifies the path to an audio .wav file for alert sounds.

Dependencies:
- Python 3.x
- opencv-python
- imutils
- dlib
- scipy
- pydub

This project effectively combines computer vision, machine learning, and audio processing to offer an efficient and accurate solution for drowsiness detection, addressing an important safety concern for drivers.
